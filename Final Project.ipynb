{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplar Retrieval Model(ERM) - Sieve 2001\n",
    "* Step1: **Encode cues**: profile of the stimulus examined\n",
    "* Step2: **Exemplar retrieval**: \n",
    "    - $$ similarity(j, k) = \\prod s^{d_k}$$\n",
    "        - $k$ from 1 to $j-1$;\n",
    "        - similarity: a multiplicative combination along various dimensions; \n",
    "        - $d_k$ the number of mismatching features between $j$ and $k$;\n",
    "        - $s$ the similarity of mismatching values for each feature (measuring the degree to which respondants fail to notice mismatching values: if $s=1$, the mismatch is not noticed and the similarity is not influenced by that dimension; if $s=0$, the mismatch in this dimension overrules all other dimensions and nullifies the similarity regardless of how many other matching features there are)).\n",
    "    - The probability of a previous instance $k$ is retrived given the new stimulus $j$ is observed\n",
    "$$p(retrieve\\_exemplar\\_K\\ |\\ new\\_stimulus\\_J) = \\frac{similarity(j,k)}{\\sum_k{similarity(j,k)}}$$\n",
    "\n",
    "    - The total probability of any previous TYPICAL instances are retrived given the new stimulus $j$ is observed\n",
    "$$p(k \\in T\\ |\\ new\\_stimulus\\_J) = \\frac{\\sum_{k\\in T}{similarity(j,k)}}{\\sum_{k\\in T}{similarity(j,k)}+\\sum_{k\\notin T}{similarity(j,k)}}$$\n",
    "    \n",
    "* Step3: **Balance assessment**:\n",
    "    - $$ S_N = \\sum^N_{i=1}{X_i}$$\n",
    "        - $X_i$: each of the outcomes in the sample of retrieved cases (eg: $X_i = 1$ if the $i$th exemplar is TYPICAL, and $X_i = -1$ if otherwise);\n",
    "        - $N$: constant representing the number of past cases that were retrieved on each trial at the time of the choice response\n",
    "* Step4: **Choice**: The respondent chooses the category that is favored in Step3.\n",
    "* Step5: **Probability Judgement**:\n",
    "    - $$F_{T,N} = \\frac{\\eta + N +S_N}{\\eta+\\theta +2N}$$\n",
    "        - $\\frac{\\eta}{\\eta+\\theta}$: personal probability distribution prior to any retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplar Model (Nilsson 2008)\n",
    "* The probability that object $t$ belongs to Category $A$:\n",
    "    - $$p(A) = \\frac{\\sum_{t}{similarity(t\\ |\\ x_i)}*c(x_i)}{\\sum_t{similarity(t\\ |\\ x_i)}}$$\n",
    "        - $x_i$: exemplars from memory $i = 1, 2, ..., I$\n",
    "        - $c(x_i) = 1$ if $x_1$ belong to $A$; $c(x_i)= 0$ otherwise.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Simulation data from Nilsson 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category structure with the 12 unique exemplars and their presentation frequency in each category\n",
      "\n",
      "['E', 'C1', 'C2', 'C3', 'C4', 'FreqA', 'FreqB']\n",
      "['E1', '0', '0', '0', '0', '0', '14']\n",
      "['E2', '0', '0', '0', '1', '0', '6']\n",
      "['E3', '0', '0', '1', '0', '0', '1']\n",
      "['E4', '0', '1', '0', '0', '0', '1']\n",
      "['E5', '1', '0', '0', '0', '5', '1']\n",
      "['E6', '0', '1', '1', '0', '1', '1']\n",
      "['E7', '1', '0', '0', '1', '1', '1']\n",
      "['E8', '0', '1', '1', '1', '6', '0']\n",
      "['E9', '1', '0', '1', '1', '1', '0']\n",
      "['E10', '1', '1', '0', '1', '1', '0']\n",
      "['E11', '1', '1', '1', '0', '1', '5']\n",
      "['E12', '1', '1', '1', '1', '14', '0']\n"
     ]
    }
   ],
   "source": [
    "file = open(\"data/Sim_Nilsson_2008.txt\")\n",
    "title = file.readline()\n",
    "col_title = file.readline().strip().split(\" \")\n",
    "exemplar_list = []\n",
    "for line in file:\n",
    "    line = line.strip()\n",
    "    if (line):\n",
    "        exemplar = line.split(\" \")\n",
    "        exemplar_list.append(exemplar)\n",
    "print(title)\n",
    "print(col_title)\n",
    "for exemplar in exemplar_list:\n",
    "    print(exemplar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two most important feature combinations are E5 and E11 (further on referred to as critical exemplars). The critical exemplars share a low number of features with the members of the category they belong more often to (0.96 features on average) and a high number of features with the category they belong less often to (2.53 features on average). Remember, a representativeness effect occurs when an object is judged as belonging to a category to which it seldom belongs only because it shares a high number of features with the members of that category. Accordingly, representativeness effects are hypothesized to occur in the probability judgments of the critical exemplars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from datetime import datetime\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step -1: Read files\n",
    "def read_features(filename):\n",
    "    file = open(filename)\n",
    "    features = []\n",
    "    for line in file:\n",
    "        features.append(line.strip())\n",
    "    return features\n",
    "\n",
    "def read_distribution(filename):\n",
    "    file = open(filename)\n",
    "    categories = file.readline().strip().split(\",\")\n",
    "    distribution = []\n",
    "    for line in file:\n",
    "        prob = line.strip().split(\",\")\n",
    "        for i in range(len(prob)):\n",
    "            prob[i] = float(prob[i])\n",
    "        prob = np.array(prob)\n",
    "        distribution.append(prob)\n",
    "    distribution = np.array(distribution)    \n",
    "    return categories, distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Around 30 years old', 'Single', 'Outspoken', 'Intelligent', 'Humanities major', 'Concerned with discrimination and social justice', 'Participated in demonstrations', 'Female']\n",
      "['B', 'F', 'NotB_NotF', 'BF']\n",
      "[[ 0.7  0.4  0.3  0.7]\n",
      " [ 0.4  0.8  0.5  0.8]\n",
      " [ 0.3  0.8  0.4  0.8]\n",
      " [ 0.5  0.7  0.5  0.7]\n",
      " [ 0.2  0.8  0.5  0.8]\n",
      " [ 0.4  0.9  0.4  0.9]\n",
      " [ 0.2  0.8  0.2  0.8]\n",
      " [ 0.8  0.9  0.5  0.9]]\n"
     ]
    }
   ],
   "source": [
    "features = read_features(\"data/linda_adjectives.txt\")\n",
    "categories, distribution = read_distribution(\"data/linda_distribution.txt\")\n",
    "print(features)\n",
    "print(categories)\n",
    "print(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Generate exemplars\n",
    "def generate_exemplars(features, distribution, category_index, numExemplars):\n",
    "    distr_category = distribution[:,category_index]\n",
    "    exemplars = []\n",
    "    for i in range(numExemplars):\n",
    "        exemplar = np.zeros(len(features))        \n",
    "        for j in range(len(distr_category)):\n",
    "            random.seed(datetime.now())\n",
    "            n = random.random()\n",
    "            if (n >= (1-distr_category[j])):\n",
    "                exemplar[j] = 1\n",
    "        exemplars.append(exemplar)\n",
    "    exemplars = np.array(exemplars)\n",
    "    return exemplars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B: [[ 1.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  1.  1.  0.  1.  1.  1.]\n",
      " [ 1.  0.  0.  0.  0.  0.  1.  1.]]\n",
      "F: [[ 0.  0.  1.  1.  1.  1.  0.  0.]\n",
      " [ 0.  1.  1.  1.  1.  1.  1.  0.]]\n",
      "NBNF: [[ 0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  1.  1.]\n",
      " [ 0.  0.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  1.]]\n",
      "FB: [[ 0.  1.  1.  1.  1.  1.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "bank_teller_exemplars = generate_exemplars(features, distribution, 0, 3)\n",
    "feminist_exemplars = generate_exemplars(features, distribution, 1, 2)\n",
    "not_bank_not_feminist_exemplars = generate_exemplars(features, distribution, 2, 5)\n",
    "feminist_banker_exemplars = generate_exemplars(features, distribution, 3, 1)\n",
    "print(\"B:\",bank_teller_exemplars)\n",
    "print(\"F:\",feminist_exemplars)\n",
    "print(\"NBNF:\",not_bank_not_feminist_exemplars)\n",
    "print(\"FB:\",feminist_banker_exemplars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  1.  1.  0.  1.  1.  1.]\n",
      " [ 1.  0.  0.  0.  0.  0.  1.  1.]\n",
      " [ 0.  0.  1.  1.  1.  1.  0.  0.]\n",
      " [ 0.  1.  1.  1.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  1.  1.]\n",
      " [ 0.  0.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  1.]\n",
      " [ 0.  1.  1.  1.  1.  1.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "all_exemplars = np.concatenate((bank_teller_exemplars, feminist_exemplars, not_bank_not_feminist_exemplars, feminist_banker_exemplars))\n",
    "print(all_exemplars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 2: exemplar retrieval\n",
    "def similarity(j,k,feat_weights):\n",
    "    simil = 1\n",
    "    for i in range(len(j)):\n",
    "        # let s for every dimension be 0.5 so every dim is equal for now\n",
    "        # for now, each dimension only has one feature which is binary\n",
    "        s = feat_weights[i]\n",
    "        if j[i] == k[i]:\n",
    "            s = s**0\n",
    "        simil = simil * s\n",
    "    return simil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ similarity(j, k) = \\prod s^{d_k}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "feat_weights = [0.5,0.5,0.5,0.5]\n",
    "print(similarity(['0','0','0','0'],['0','0','0','1'],feat_weights))\n",
    "print(similarity(['0','0','0','0'],['0','0','1','1'],feat_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_retrieve_k(exemplar_list, j, k, feat_weights):\n",
    "    # probability of retrieve a single instance\n",
    "    inMem = 0\n",
    "    for exemplar in exemplar_list:\n",
    "        if np.array_equal(k, exemplar):\n",
    "            inMem = 1\n",
    "            break\n",
    "    if inMem == 0:\n",
    "        return 0\n",
    "    total = 0\n",
    "    sim_jk = similarity(j,k,feat_weights)\n",
    "    for i in exemplar_list:\n",
    "        sim_ji = similarity(j,i,feat_weights)\n",
    "        total += sim_ji\n",
    "    prob = sim_jk/total\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p(retrieve\\_exemplar\\_K\\ |\\ new\\_stimulus\\_J) = \\frac{similarity(j,k)}{\\sum_k{similarity(j,k)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8767123287671232\n",
      "0\n",
      "0.6153846153846154\n",
      "0.9999999999999997\n"
     ]
    }
   ],
   "source": [
    "feat_weights = [0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5]\n",
    "test = np.array([ 1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
    "print(prob_retrieve_k(bank_teller_exemplars, test, test, feat_weights))\n",
    "print(prob_retrieve_k(feminist_exemplars, test, test, feat_weights))\n",
    "print(prob_retrieve_k(all_exemplars, test, test, feat_weights))\n",
    "\n",
    "\n",
    "total = 0\n",
    "for exemplar in all_exemplars:\n",
    "    total += prob_retrieve_k(all_exemplars, test, exemplar, feat_weights)\n",
    "print(total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
